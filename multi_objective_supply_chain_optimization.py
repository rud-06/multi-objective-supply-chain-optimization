# -*- coding: utf-8 -*-
"""Resilient_Supply_Chain_Optimizer.ipynb

Automatically generated by Colab.
"""

# ==========================================
# 1. SETUP & LIBRARIES
# ==========================================
# Uncomment the lines below if running in Google Colab
# !pip install pulp plotly pandas numpy matplotlib

import pulp
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt

# Set random seed for reproducibility
np.random.seed(42)

print("Libraries loaded successfully.")

# ==========================================
# 2. DATA GENERATION
# ==========================================

# Define raw supplier data
data = {
    "Supplier": ["S1_Germany", "S2_Vietnam", "S3_China", "S4_SKorea",
                 "S5_USA", "S6_UAE", "S7_Brazil", "S8_Indonesia",
                 "S9_Japan", "S10_Thailand"],
    "Country": ["Germany", "Vietnam", "China", "South Korea",
                "USA", "UAE", "Brazil", "Indonesia",
                "Japan", "Thailand"],
    "Unit_Cost": [12, 9, 8, 11, 13, 10, 9.5, 8.5, 12.5, 9],
    "Lead_Time_Days": [30, 18, 15, 20, 35, 12, 28, 16, 22, 17],
    "Capacity": [3000, 2000, 2500, 1800, 2200, 1500, 1700, 2000, 1600, 2100],
    "Distance_km": [6500, 3000, 4500, 5000, 12000, 2500, 14000, 4000, 6000, 3500],
    "Carbon_per_km": [0.02, 0.018, 0.021, 0.019, 0.025, 0.017, 0.026, 0.02, 0.022, 0.018],
    "Geopolitical_Risk": [2, 4, 6, 3, 3, 2, 5, 4, 2, 3],
    "Port_Risk": [3, 5, 7, 4, 4, 3, 6, 5, 3, 4],
    "Reliability_Rate": [0.95, 0.9, 0.85, 0.92, 0.93, 0.96, 0.88, 0.89, 0.94, 0.91]
}

df = pd.DataFrame(data)

# Feature Engineering: Calculate Risk and Carbon metrics
df["Carbon_Impact_Per_Unit"] = df["Distance_km"] * df["Carbon_per_km"]
df["Composite_Risk"] = (0.6 * df["Geopolitical_Risk"] + 0.4 * df["Port_Risk"])
df["Risk_Adjusted_Cost"] = df["Unit_Cost"] * (1 + df["Composite_Risk"]/10)

# Define Warehouses and Demand
warehouses = ["W1_North", "W2_South", "W3_East", "W4_West"]
warehouse_demand = {w: 1000 for w in warehouses} # Total demand 4000

# Create Global Lookup Dictionaries (Used by the solver)
suppliers = df["Supplier"].tolist()
supplier_capacity_dict = df.set_index("Supplier")["Capacity"].to_dict()

# Simulate Cost, Risk, and Carbon Matrices (Supplier x Warehouse)
# In a real project, these would be specific to each warehouse location.
cost_matrix = pd.DataFrame(
    np.random.rand(len(suppliers), len(warehouses)) * 5 + 5, # Costs between 5-10
    index=suppliers, columns=warehouses
)

risk_matrix = pd.DataFrame(
    np.random.rand(len(suppliers), len(warehouses)) * 3 + 1, # Risk factors 1-4
    index=suppliers, columns=warehouses
)

carbon_matrix = pd.DataFrame(
    np.random.rand(len(suppliers), len(warehouses)) * 0.1 + 0.05, # Carbon 0.05-0.15
    index=suppliers, columns=warehouses
)

print("Data generation complete.")

# ==========================================
# 3. EXPLORATORY DATA ANALYSIS (EDA)
# ==========================================

# Chart 1: Cost vs Speed vs Risk
fig1 = px.scatter(
    df,
    x="Unit_Cost",
    y="Lead_Time_Days",
    size="Composite_Risk",
    color="Composite_Risk",
    hover_name="Supplier",
    title="Supplier Analysis: Cost vs Speed (Size = Risk)",
    color_continuous_scale="RdYlGn_r" # Green is low risk, Red is high
)
fig1.show()

# Chart 2: Risk vs Cost vs Carbon
fig2 = px.scatter(
    df,
    x="Composite_Risk",
    y="Unit_Cost",
    size="Carbon_Impact_Per_Unit",
    color="Carbon_Impact_Per_Unit",
    hover_name="Supplier",
    title="Sustainability Check: Risk vs Cost (Size = Carbon Impact)",
)
fig2.show()

# ==========================================
# 4. THE OPTIMIZATION ENGINE
# ==========================================

def solve_supply_chain(w_cost, w_risk, w_carbon, custom_capacity=None):
    """
    Solves the LP problem for specific weights and optional capacity constraints.
    Returns: (Total Cost, Total Risk, Total Carbon)
    """
    # Use default capacity if no custom one is provided
    current_capacity = custom_capacity if custom_capacity else supplier_capacity_dict

    # Initialize Model
    model = pulp.LpProblem("SupplyChainOptimization", pulp.LpMinimize)

    # Decision Variables: How much to ship from Supplier i to Warehouse j
    shipment = pulp.LpVariable.dicts(
        "Ship",
        [(i, j) for i in suppliers for j in warehouses],
        lowBound=0,
        cat='Continuous'
    )

    # Objective Function: Minimize Weighted Sum of Cost, Risk, and Carbon
    model += pulp.lpSum([
        shipment[(i,j)] * (
            w_cost * cost_matrix.loc[i,j] +
            w_risk * risk_matrix.loc[i,j] +
            w_carbon * carbon_matrix.loc[i,j]
        )
        for i in suppliers for j in warehouses
    ])

    # Constraint 1: Supplier Capacity (Cannot exceed what they have)
    for i in suppliers:
        model += pulp.lpSum([shipment[(i,j)] for j in warehouses]) <= current_capacity[i]

    # Constraint 2: Warehouse Demand (Must meet exact demand)
    for j in warehouses:
        model += pulp.lpSum([shipment[(i,j)] for i in suppliers]) == warehouse_demand[j]

    # Constraint 3: Risk Diversification (No single supplier > 60% of a warehouse's needs)
    for i in suppliers:
        for j in warehouses:
            model += shipment[(i,j)] <= 0.6 * warehouse_demand[j]

    # Solve
    model.solve(pulp.PULP_CBC_CMD(msg=False)) # msg=False hides the solver log

    # Check if a solution was found
    if pulp.LpStatus[model.status] != 'Optimal':
        return None, None, None

    # Calculate Totals for Reporting
    total_cost = sum(shipment[(i,j)].varValue * cost_matrix.loc[i,j] for i in suppliers for j in warehouses)
    total_risk = sum(shipment[(i,j)].varValue * risk_matrix.loc[i,j] for i in suppliers for j in warehouses)
    total_carbon = sum(shipment[(i,j)].varValue * carbon_matrix.loc[i,j] for i in suppliers for j in warehouses)

    return total_cost, total_risk, total_carbon

print("Optimization Engine Ready.")

# ==========================================
# 5. SCENARIO ANALYSIS
# ==========================================

scenarios = {
    "Cost Focused": (0.8, 0.1, 0.1),  # Mainly cares about money
    "Risk Focused": (0.3, 0.6, 0.1),  # Mainly cares about safety
    "Green Focused": (0.3, 0.1, 0.6)  # Mainly cares about environment
}

results = {}
for name, (wc, wr, wcarb) in scenarios.items():
    results[name] = solve_supply_chain(wc, wr, wcarb)

# Convert results to DataFrame for easy viewing
results_df = pd.DataFrame(results, index=["Total Cost", "Total Risk", "Total Carbon"]).T

# Normalize for visualization (0-1 Scale)
normalized_df = (results_df - results_df.min()) / (results_df.max() - results_df.min())

# Plot Comparison
normalized_df.plot(kind='bar', figsize=(10, 6))
plt.title("Scenario Trade-offs (Normalized 0-1)")
plt.ylabel("Relative Impact (Lower is Better)")
plt.xticks(rotation=0)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

print("Scenario Analysis Complete.")
display(results_df)

# ==========================================
# 6. RESILIENCE STRESS TESTING
# ==========================================
# Scenario: What if Vietnam (S2) faces a lockdown and capacity drops by 70%?

print("\n--- Running Stress Test: 'Vietnam Lockdown' ---")

# Create Shocked Capacity Dictionary
shocked_capacity = supplier_capacity_dict.copy()
shocked_capacity["S2_Vietnam"] = shocked_capacity["S2_Vietnam"] * 0.3

# Run Baseline (Normal) vs Shocked
cost_w, risk_w, carb_w = 0.5, 0.3, 0.2  # Balanced weights
normal_res = solve_supply_chain(cost_w, risk_w, carb_w, supplier_capacity_dict)
shock_res = solve_supply_chain(cost_w, risk_w, carb_w, shocked_capacity)

# Calculate Impact
cost_increase = ((shock_res[0] - normal_res[0]) / normal_res[0]) * 100
resilience_score = 1 / (1 + (cost_increase/100))

print(f"Normal Cost: ${normal_res[0]:,.2f}")
print(f"Shock Cost:  ${shock_res[0]:,.2f}")
print(f"Cost Surge:  {cost_increase:.2f}%")
print(f"Resilience Score: {resilience_score:.4f} (Scale 0-1)")

# ==========================================
# 7. PARETO OPTIMIZATION (THE "KNEE" POINT)
# ==========================================
# Finding the perfect balance between Cost and Risk

cost_weights = np.linspace(0, 1, 20)
pareto_points = []

for wc in cost_weights:
    remaining = 1 - wc
    wr = remaining / 2  # Split remaining weight between risk and carbon
    wcarb = remaining / 2
    
    res = solve_supply_chain(wc, wr, wcarb)
    if res[0] is not None:
        pareto_points.append(res)

# Extract Cost and Risk for plotting
costs = np.array([p[0] for p in pareto_points])
risks = np.array([p[1] for p in pareto_points])

# Normalization for Knee Point Detection
c_norm = (costs - costs.min()) / (costs.max() - costs.min())
r_norm = (risks - risks.min()) / (risks.max() - risks.min())

# Find the Knee (Point closest to origin 0,0 in normalized space)
distances = np.sqrt(c_norm**2 + r_norm**2)
knee_idx = np.argmin(distances)

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(costs, risks, marker='o', linestyle='-', label='Pareto Frontier')
plt.scatter(costs[knee_idx], risks[knee_idx], color='red', s=150, label='Optimal "Knee" Point', zorder=5)

plt.title("Pareto Frontier: Cost vs. Risk Trade-off")
plt.xlabel("Total Supply Chain Cost ($)")
plt.ylabel("Total Risk Exposure (Score)")
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()
plt.show()

print(f"Optimal Strategy Found at:")
print(f"Cost: ${costs[knee_idx]:,.2f}")
print(f"Risk: {risks[knee_idx]:.2f}")